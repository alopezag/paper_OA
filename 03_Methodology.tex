\section{Methodology}\label{sec:Methodology}

...

\subsection{Digital Assistant}\label{sec:DA}

Speech, which is the prevalent way to interact with a DA, is characterized by high efficiency, naturalness, low cognitive load and hands-free capabilities. However, it is hard when it is noisy or multiple persons are working in close proximity \cite{hou2018VisualFeedbackDesign}. Speech, however, can be complemented by graphical UIs to query a DA, for instance, through a chatbot and touch/gestural interaction \cite{belkadi2020IntelligentAssistantSystem,klopfenstein2017RiseBotsSurvey,heller2019TaskHerderWearableMinimal}. Leveraging multiple modalities and devices in combination with a conversational UI allows seamless interaction \cite{white2019MultideviceDigitalAssistance}, as well as taking advantage of fitting technologies in different situations \cite{heinz2018MultideviceAssistiveSystem}. Therefore, we will support multiple devices and modalities to interact with the DA, using web-based multi-device formats. Interaction between the operator and DA will always happen through a UI on a device, which needs to be created for and tailored to that specific device for an optimal experience. Automatic UI creation and adaptation mechanisms, however, are error prone and complex, and lack control, transparency and predictability \cite{lavie2010BenefitsCostsAdaptive}. On the work floor, operators require stable interfaces that are predictable. Therefore, we focus on an adaptable UI \cite{bunt2007SupportingInterfaceCustomization} and design templates that take into account best practices \cite{ratzka2013UserInterfacePatterns} to ensure a consistent and usable experience. In contrast to existing work, we will use a holistic approach that considers (i) context, devices, modalities, and UI together, (ii) from both a technical and usability perspective, (iii) in a manufacturing setting: we will provide a toolbox for multimodal UIs that can be rendered on multiple devices and support seamless two-way interaction, which can be optimized for the current manufacturing environment, task and operator (see figure 1 for a practical example). We will build on our experiences with, among others, asking and answering questions about computing applications \cite{vermeulen2010PervasiveCrystalAskingAnswering}.


\subsection{Reactive and proactive support} \label{sec:ReactiveProactive}

A major benefit of the DA is the on-demand, reactive nature of support, as nonstop support can negatively influence task completion time and perceived cognitive load \cite{funk2017WorkingAugmentedReality}. The downside is that the information might be overlooked by the operator. Therefore, the DA will offer proactive assistance when needed (e.g., in case of errors in task execution) \cite{cuenca2016HasseltRapidPrototyping}. 

We will investigate decision strategies that use implicit inputs such as cognitive load \cite{lindlbauer2019ContextAwareOnlineAdaptation}, state estimation and proxemics \cite{Marquardt_2015} \cite{Williamson_2022}. Proactivity, however, will always be imperfect, akin to inevitable flaws in activity and context detection: we will implement a two-way feedback loop so the operator can complement or correct info (e.g., in case of low confidence level of an activity recognition or additional information offered because of a lack of experience, the operator is made aware and can intervene). 
To process both explicit and implicit inputs, we will build on our experiences with prototyping multimodal interactions \cite{eshet2016ContextUseFinal}, as it is not our goal to advance the state of the art with regard to low-level input processing. 

We will also implement strategies to attune the output to the context of use (e.g., the operator's experience, the task's criticality, and the probability of errors). To this end, we will render information with various levels of detail \cite{Mezhoudi2015AnAA}, \cite{10.1145/3332165.3347945}, adapted to a manufacturing setting and augmented with a mixed-initiative approach to keep the operator in control. An inexperienced operator, for instance, will be offered more detailed information (e.g., instructional video or diagram instead of text) and more frequent proactive suggestions, but the operator can always intervene to avoid unwanted or unneeded behavior.

\subsection{Knowledge representation}

The support offered by the DA is based on rich and in-depth knowledge of the assembly process, obtained by connecting various information sources (e.g., MES, application services). The concept of Virtual Knowledge Graphs (VKG) \cite{xiao2019VirtualKnowledgeGraphs} will be used to represent and store available knowledge in a dynamic Assembly Knowledge Store (AKS). The elements that define a VKG are (i) an ontology schema that provides semantics and structures the data for a specific domain, (ii) one or more information sources, and (iii) a mapping that effectuates the migration of data from these sources to an ontology. 

Three domain ontologies will be created and brought together throughout the project to realize the AKS, as depicted in Table \ref{tab:ontolgoies}. During the development of the domain ontologies, semantic rule axioms \cite{sormaz2019SIMPMUpperlevelOntology} for each domain will be authored using Semantic Web Rule Language (SWRL) to derive knowledge from the data and identify potential mismatches automatically. These rule axioms will facilitate the maintenance and functioning of the AKS.

\begin{table}
  \caption{Domain ontologies}
  \label{tab:ontolgoies}
  \begin{tabular}{cp{7cm}}
    \toprule
    Domain & Description\\
    \midrule
    Assembly Domain Ontology &  A combination between the ISA-95 based assembly information model \cite{claeys2018OntologicalModelManaging} and a skill-based resource library.\\ 
    Questions \& Answers Domain & Describe possible question-answer pairs and map them to entities from the assembly information domain. \\
    Conversational History Domain & Capture the real assembly runs when operators are assisted by the DA.\\
    \bottomrule
  \end{tabular}
\end{table}

%The assembly information domain where the ISA-95 based assembly information model (ICON OperatorKnowledge) [12] and skill-based resource library (Flexas-VR) will be unified in the AKS to structure and represent assembly context information (maximally exploiting existing standards, e.g., RAMI4.0, Open Assembly Model). The VKG approach enables the dynamic migration of additional data from different information systems based on the use case requirements.
%The Questions and Answers (Q\&A) domain will describe possible question-answer pairs and map them to entities from the assembly information domain (e.g., link a question to a specific piece of equipment). The observation of industrial cases and interviews with all stakeholders, mentioned before, will result in an overview of common questions or requests in an assembly/maintenance environment, which will be used to populate the Q\&A domain.
%The conversational history data will be initiated by real assembly runs in the lab, where operators are assisted by the DA.

\subsection{Context estimation}

The action recognizer will evaluate the position of all relevant objects and persons in the environment and compare these locations to a spatial grid that describes all regions of interest. To capture the full extent of the assembly procedure, we will fuse data from various sensors (multiple RGB-sensors, UWB, RFID, torque tool loggings). As a last increment to the action recognition, feedback from the assembly state estimator will be used to narrow down potential actions and thus objects and regions to focus on. Such multi-sensor systems are often expensive, and the resolution and accuracy requirements are largely dependent on the environment. For example, rough information about the operator's location and trajectory might already suffice in recognizing actions in repetitive environments \cite{bauters2018AutomatedWorkCycle}. Therefore, we will investigate how the requirements for sensor accuracy and resolution vary in different environments, in order to derive guidelines to obtain the most cost-effective solution for a specific case. The detected action sequence will then be classified (e.g., Hidden Markov Model \cite{cramer2018RobustIntentionEstimation}) as an assembly state, based on knowledge about predefined or prerecorded action sequences stored in the AKS. This output, combined with the outputs of the existing hand, object and tool tracking, will be used to provide the DA with an estimation of the actual state of the assembly process. The developed ASE solutions and contextual information available in the AKS may not be sufficient for the reasoning engine in some cases. The most logical way to retrieve this missing context information is by interacting with the operator through the DA User Interface.

\subsection{Intelligent support}

The reasoning engine (RE) exploited the knowledge stored in the AKS and context information obtained through state monitoring or interaction with the operator to adapt the content offered to the operator in view of the operator's context and needs. 
An iterative, phased approach will be used, incrementally increasing the functionalities of the RE throughout the project. 
We will first build a basic recommender filter to validate the concept, before gradually replacing parts of it to increase functionality (and complexity). Hence, as a starting point, a rule-based recommender that filters potentially relevant questions or actions from a predefined FAQ, based on perfect context information, will be designed. To do this, assembly context will be translated into exact rules that are used as filters, using a probabilistic process descriptors-based approach. 
In a second iteration, questions will be combined and stored as a generic question, where a question asked by the operator is a query with variable context parameters. This omits the need for a predefined FAQ. To determine the answer to these questions, we will explore a fusion of existing data-driven classification techniques with context descriptors to form decision tree structures [21]. When no suitable answer is available in the AKS, questions will be pushed to experts and the decision trees will be extended by formalizing their feedback, reinforcing the decision tree for future applications.
In this context, we will investigate transferability of reinforced learning approaches for data-rich environments (e.g., deep learning techniques) to a data-scarce context [22]. Finally, the RE functionality will be extended to cope with incomplete or imperfect context information. A method that implies context parameters based on available knowledge will be developed. This is typically done with techniques that rely on removal of features, which are not applicable in a data-scarce environment. Hence, we will explore predictive methods to replace missing data where possible.
